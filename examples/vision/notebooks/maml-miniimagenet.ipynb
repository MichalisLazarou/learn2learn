{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/michalislazarou/PhD/learn2learn/examples/vision/notebooks', '/home/michalislazarou/anaconda3/envs/metal2/lib/python37.zip', '/home/michalislazarou/anaconda3/envs/metal2/lib/python3.7', '/home/michalislazarou/anaconda3/envs/metal2/lib/python3.7/lib-dynload', '', '/home/michalislazarou/anaconda3/envs/metal2/lib/python3.7/site-packages', '/home/michalislazarou/anaconda3/envs/metal2/lib/python3.7/site-packages/IPython/extensions', '/home/michalislazarou/.ipython', '../../../learn2learn', '../../../learn2learn']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "sys.path.append('../../../learn2learn') \n",
    "\n",
    "import numpy as np\n",
    "import torch as th\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.autograd import grad\n",
    "import learn2learn as l2l\n",
    "from learn2learn.data.transforms import NWays, KShots, LoadData, RemapLabels, ConsecutiveLabels\n",
    "print(sys.path)\n",
    "import algorithms.maml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables to change\n",
    "train_dataset = l2l.vision.datasets.MiniImagenet(root='../data', mode='train')\n",
    "valid_dataset = l2l.vision.datasets.MiniImagenet(root='../data', mode='validation')\n",
    "test_dataset = l2l.vision.datasets.MiniImagenet(root='../data', mode='test')\n",
    "train_dataset = l2l.data.MetaDataset(train_dataset)\n",
    "valid_dataset = l2l.data.MetaDataset(valid_dataset)\n",
    "test_dataset = l2l.data.MetaDataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_loss(grad0, grad1):\n",
    "    loss = th.zeros(1)\n",
    "    for i in range(len(grad0)):\n",
    "       # print(i)\n",
    "      #  print(list(grad0[i].size()))\n",
    "        product = th.mm(grad0[i], grad1[i])\n",
    "        loss = loss +th.sum(product)\n",
    "    return loss\n",
    "    \n",
    "def accuracy(predictions, targets):\n",
    "    predictions = predictions.argmax(dim=1).view(targets.shape)\n",
    "    return (predictions == targets).sum().float() / targets.size(0)\n",
    "\n",
    "def transformbatch(batch, transformer):\n",
    "    data, labels = batch\n",
    "    data, labels = data.to(device), labels.to(device)\n",
    "    data_transformed = transformer(data)\n",
    "    return [data_transformed, labels]\n",
    "\n",
    "def fast_adapt(batch, learner, loss, adaptation_steps, shots, ways, device):\n",
    "    data, labels = batch\n",
    "    data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "    # Separate data into adaptation/evalutation sets\n",
    "    adaptation_indices = th.zeros(data.size(0)).byte()\n",
    "    adaptation_indices[th.arange(shots*ways) * 2] = 1\n",
    "  #  print(adaptation_indices.size())\n",
    "    adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
    "   # print(adaptation_labels.size())\n",
    "    evaluation_data, evaluation_labels = data[1 - adaptation_indices], labels[1 - adaptation_indices]\n",
    "    \n",
    "    #before adaptation, get the needed parameters for adaptation of transformer\n",
    "    L0 = loss(learner(adaptation_data), adaptation_labels)\n",
    "    L1 = loss(learner(evaluation_data), evaluation_labels)\n",
    "     # Adapt the model\n",
    "    for step in range(adaptation_steps):\n",
    "        train_error = loss(learner(adaptation_data), adaptation_labels)\n",
    "        train_error /= len(adaptation_data)\n",
    "        learner.adapt(train_error)\n",
    "\n",
    "    # Evaluate the adapted model\n",
    "    predictions = learner(evaluation_data)\n",
    "    valid_error = loss(predictions, evaluation_labels)\n",
    "   # print(valid_error)\n",
    "    valid_error /= len(evaluation_data)\n",
    "    valid_accuracy = accuracy(predictions, evaluation_labels)\n",
    "    return valid_error, valid_accuracy, L0, L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ways=5\n",
    "shots=5\n",
    "meta_lr=0.003\n",
    "fast_lr=0.5\n",
    "meta_batch_size=32\n",
    "adaptation_steps=1\n",
    "num_iterations=5\n",
    "cuda=True\n",
    "seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "th.manual_seed(seed)\n",
    "device = th.device('cpu')\n",
    "if cuda and th.cuda.device_count():\n",
    "    th.cuda.manual_seed(seed)\n",
    "    device = th.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = [NWays(train_dataset, ways),KShots(train_dataset, 2*shots),LoadData(train_dataset),\n",
    "        RemapLabels(train_dataset),\n",
    "        ConsecutiveLabels(train_dataset),\n",
    "    ]\n",
    "train_tasks = l2l.data.TaskDataset(train_dataset, task_transforms=train_transforms,num_tasks=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_transforms = [NWays(valid_dataset, ways), KShots(valid_dataset, 2*shots), LoadData(valid_dataset),\n",
    "        ConsecutiveLabels(train_dataset),\n",
    "        RemapLabels(valid_dataset),\n",
    "    ]\n",
    "valid_tasks = l2l.data.TaskDataset(valid_dataset, task_transforms=valid_transforms, num_tasks=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = [NWays(test_dataset, ways), KShots(test_dataset, 2*shots), LoadData(test_dataset), \n",
    "        RemapLabels(test_dataset),\n",
    "        ConsecutiveLabels(train_dataset),\n",
    "    ]\n",
    "test_tasks = l2l.data.TaskDataset(test_dataset, task_transforms=test_transforms, num_tasks=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of MiniImagenetCNN(\n",
      "  (base): ConvBase(\n",
      "    (0): ConvBlock(\n",
      "      (max_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (normalize): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1): ConvBlock(\n",
      "      (max_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (normalize): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (2): ConvBlock(\n",
      "      (max_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (normalize): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (3): ConvBlock(\n",
      "      (max_pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
      "      (normalize): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "      (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=800, out_features=64, bias=True)\n",
      ")>\n",
      "LinearBlock(\n",
      "  (relu): ReLU()\n",
      "  (normalize): BatchNorm1d(5, eps=0.001, momentum=0.999, affine=True, track_running_stats=False)\n",
      "  (linear): Linear(in_features=64, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create models, 2 networks, one is the transformer (conditioned on gradients of minibatches)\n",
    "# the other is the meta-learner doing MAML\n",
    "embedding = 64\n",
    "#same as miniImagenetCNN to learn the latent space/conditioned on the gradients,\n",
    "#used size 64 like LEO encoder\n",
    "transformer = l2l.vision.models.MiniImagenetCNN(embedding)\n",
    "transformer.to(device)\n",
    "metal = l2l.vision.models.LinearBlock(embedding, ways)\n",
    "metal.to(device)\n",
    "maml = algorithms.maml.MAML(metal, lr=fast_lr, first_order=False)\n",
    "opt = optim.Adam(maml.parameters(), meta_lr)\n",
    "opt_transform = optim.Adam(transformer.parameters(), meta_lr)\n",
    "loss = nn.CrossEntropyLoss(reduction='mean')\n",
    "print(transformer.parameters)\n",
    "print(metal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "torch.Size([5])\n",
      "torch.Size([5])\n",
      "torch.Size([5, 64])\n",
      "torch.Size([5])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1573049306803/work/aten/src/ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.\n",
      "/opt/conda/conda-bld/pytorch_1573049306803/work/aten/src/ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.\n",
      "/opt/conda/conda-bld/pytorch_1573049306803/work/aten/src/ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.\n",
      "/opt/conda/conda-bld/pytorch_1573049306803/work/aten/src/ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9676e16214d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m            \u001b[0;31m#    print(gradients0[i].size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m            \u001b[0mgradients1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m            \u001b[0mloss_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradients1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m            \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_transformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m            \u001b[0;31m#loss_transformer.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-86c819867fe2>\u001b[0m in \u001b[0;36mtransformer_loss\u001b[0;34m(grad0, grad1)\u001b[0m\n\u001b[1;32m      4\u001b[0m        \u001b[0;31m# print(i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0;31m#  print(list(grad0[i].size()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mproduct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    " for iteration in range(num_iterations):\n",
    "        opt.zero_grad()\n",
    "        meta_train_error = 0.0\n",
    "        meta_train_accuracy = 0.0\n",
    "        meta_valid_error = 0.0\n",
    "        meta_valid_accuracy = 0.0\n",
    "        meta_test_error = 0.0\n",
    "        meta_test_accuracy = 0.0\n",
    "        for task in range(meta_batch_size):\n",
    "            # Compute meta-training loss\n",
    "            learner = maml.clone()\n",
    "            batch = train_tasks.sample()\n",
    "            #print(batch[0].size())\n",
    "            batch_transformed = transformbatch(batch, transformer)\n",
    "            evaluation_error, evaluation_accuracy, L0, L1 = fast_adapt(batch_transformed, learner, loss, adaptation_steps, shots, ways,\n",
    "                           device)\n",
    "            \n",
    "            #check the gradients, torch.autograd.grad does not accumulate gradients ;)\n",
    "           # print(\"maml\")\n",
    "            #for p in maml.parameters():\n",
    "              #  print(p.grad)\n",
    "           # print(\"transformer\")\n",
    "            #for p in transformer.parameters():\n",
    "             #   print(p.grad)\n",
    "            gradients0 = grad(L0, maml.parameters(), retain_graph=True, create_graph=True)\n",
    "           # print(\"after\")\n",
    "            #for p in maml.parameters():\n",
    "             #   print(p.grad)\n",
    "            #print(\"gradients\")\n",
    "           # print(len(gradients0))\n",
    "            #for i in range(len(gradients0)):\n",
    "            #    print(gradients0[i].size())\n",
    "            gradients1 = grad(L1, maml.parameters(), retain_graph=True, create_graph=True)\n",
    "            loss_transformer = transformer_loss(gradients0, gradients1)\n",
    "            print(loss_transformer)\n",
    "            #loss_transformer.backward()\n",
    "            evaluation_error.backward()\n",
    "            meta_train_error += evaluation_error.item()\n",
    "            meta_train_accuracy += evaluation_accuracy.item()\n",
    "\n",
    "            # Compute meta-validation loss\n",
    "            learner = maml.clone()\n",
    "            batch = valid_tasks.sample()\n",
    "            batch_transformed = transformbatch(batch, transformer)\n",
    "            evaluation_error, evaluation_accuracy, _, _ = fast_adapt(batch_transformed, learner,loss, adaptation_steps,\n",
    "                                                               shots,\n",
    "                                                               ways,\n",
    "                                                               device)\n",
    "            meta_valid_error += evaluation_error.item()\n",
    "            meta_valid_accuracy += evaluation_accuracy.item()\n",
    "\n",
    "            # Compute meta-testing loss\n",
    "            learner = maml.clone()\n",
    "            batch = test_tasks.sample()\n",
    "            batch_transformed = transformbatch(batch, transformer)\n",
    "            evaluation_error, evaluation_accuracy, _,_ = fast_adapt(batch_transformed, learner, loss, adaptation_steps,\n",
    "                                                               shots,\n",
    "                                                               ways,\n",
    "                                                               device)\n",
    "            meta_test_error += evaluation_error.item()\n",
    "            meta_test_accuracy += evaluation_accuracy.item()\n",
    "\n",
    "        # Print some metrics\n",
    "        print('\\n')\n",
    "        print('Iteration', iteration)\n",
    "        print('Meta Train Error', meta_train_error / meta_batch_size)\n",
    "        print('Meta Train Accuracy', meta_train_accuracy / meta_batch_size)\n",
    "        print('Meta Valid Error', meta_valid_error / meta_batch_size)\n",
    "        print('Meta Valid Accuracy', meta_valid_accuracy / meta_batch_size)\n",
    "        print('Meta Test Error', meta_test_error / meta_batch_size)\n",
    "        print('Meta Test Accuracy', meta_test_accuracy / meta_batch_size)\n",
    "\n",
    "        # Average the accumulated gradients and optimize., last step of meta-gradient\n",
    "        for p in maml.parameters():\n",
    "            p.grad.data.mul_(1.0 / meta_batch_size)\n",
    "        opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
